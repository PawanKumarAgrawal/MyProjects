{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtIzzHsntBSL",
        "outputId": "19aab57e-8d37-4691-d6a0-b4353dda7908"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhZMtSdM3W4N"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYkLNQfh6g9Y"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import make_scorer, mean_absolute_percentage_error\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCrakIjRollf",
        "outputId": "8fc3fa75-4422-45d3-c3db-667b04ae80d1"
      },
      "outputs": [],
      "source": [
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DYn2_6J2oYF",
        "outputId": "3d28f2a1-dafb-46e6-cc08-0338578746d1"
      },
      "outputs": [],
      "source": [
        "# Check for GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7lZjGSXR35Qz",
        "outputId": "85ce8c2c-a8a8-4071-d609-4e7307a3caf9"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/GE_train_data.csv', usecols = ['datetime', 'energy'], encoding = 'latin1')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U6WJhZi81za"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "u70Dnz9f36Yo",
        "outputId": "9f0afd2b-d10e-459b-c346-6215a45c2b5e"
      },
      "outputs": [],
      "source": [
        "df.dropna(subset = ['datetime'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFkhK1dvyzW8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert 'Order_Date' to datetime\n",
        "df['datetime'] = pd.to_datetime(df['datetime'], format='mixed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muGYWWfctQsP"
      },
      "outputs": [],
      "source": [
        "df['energy'] = df['energy'].interpolate(method='linear')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "_GK7rP2vt-B_",
        "outputId": "6097e45a-5403-45b7-d915-468c9321b2ce"
      },
      "outputs": [],
      "source": [
        "# Calculate the frequency dynamically\n",
        "freq = (df['datetime'].iloc[-1] - df['datetime'].iloc[-2]).total_seconds()\n",
        "\n",
        "# Generate the next 10,000 entries\n",
        "start_date = df['datetime'].iloc[-1]\n",
        "new_dates = pd.date_range(start=start_date + pd.Timedelta(seconds=freq),\n",
        "                          periods=17544,\n",
        "                          freq=f\"{int(freq)}S\")  # Frequency in seconds\n",
        "\n",
        "# Append the new entries to the DataFrame\n",
        "future_df = pd.DataFrame({'datetime': new_dates})\n",
        "future_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBE5oD-nurDQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vYOxNBuuq_X"
      },
      "outputs": [],
      "source": [
        "# Define a function for date-related feature engineering\n",
        "def extract_date_features(data):\n",
        "    # Extract basic date components\n",
        "    data['year'] = data['datetime'].dt.year\n",
        "    data['is_leap_year'] = data['datetime'].dt.is_leap_year.astype(int)\n",
        "    data['week_of_year'] = data['datetime'].dt.isocalendar().week\n",
        "    data['day_of_year'] = data['datetime'].dt.dayofyear\n",
        "\n",
        "    data['quarter'] = data['datetime'].dt.quarter\n",
        "\n",
        "    data['month'] = data['datetime'].dt.month\n",
        "    data['day_of_month'] = data['datetime'].dt.day\n",
        "    data['week_of_month'] = data['datetime'].dt.isocalendar().week % 4 + 1\n",
        "\n",
        "    data['day_of_week'] = data['datetime'].dt.dayofweek\n",
        "    data['is_weekend'] = data['datetime'].dt.dayofweek.isin([5, 6]).astype(int)\n",
        "\n",
        "    data['hour'] = data['datetime'].dt.hour\n",
        "    # data['minute'] = data['datetime'].dt.minute\n",
        "\n",
        "    # Add sine and cosine transformations for cyclical features\n",
        "    # Month\n",
        "    data['month_sin'] = np.sin(2 * np.pi * data['datetime'].dt.month / 12)\n",
        "    data['month_cos'] = np.cos(2 * np.pi * data['datetime'].dt.month / 12)\n",
        "\n",
        "    # Day of the week\n",
        "    data['day_of_week_sin'] = np.sin(2 * np.pi * data['datetime'].dt.dayofweek / 7)\n",
        "    data['day_of_week_cos'] = np.cos(2 * np.pi * data['datetime'].dt.dayofweek / 7)\n",
        "\n",
        "    # Hour\n",
        "    data['hour_sin'] = np.sin(2 * np.pi * data['datetime'].dt.hour / 24)\n",
        "    data['hour_cos'] = np.cos(2 * np.pi * data['datetime'].dt.hour / 24)\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0A_on4cuq75"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "v6e8bL2duq4E",
        "outputId": "fd7a5363-e971-46ec-d1c0-7bbdc2b943bf"
      },
      "outputs": [],
      "source": [
        "# Extract features and target\n",
        "df = extract_date_features(df)  # Ensure features are added for training\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJQMlwhBuq0Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uD_oTTaNuqwn"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
        "Q1 = df['energy'].quantile(0.25)\n",
        "Q3 = df['energy'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define lower and upper bounds\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Create a binary column for IQR outliers\n",
        "df['is_iqr_outlier'] = ((df['energy'] < lower_bound) | (df['energy'] > upper_bound)).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ilf1ysaDuqlb"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import zscore\n",
        "\n",
        "# Calculate Z-Score for the energy column\n",
        "df['z_score'] = zscore(df['energy'])\n",
        "\n",
        "# Define Z-Score threshold for 99% confidence\n",
        "z_threshold = 2.576\n",
        "\n",
        "# Create a binary column for Z-Score outliers\n",
        "df['is_z_outlier'] = (abs(df['z_score']) > z_threshold).astype(int)\n",
        "\n",
        "# Drop the temporary 'z_score' column if not needed\n",
        "df.drop(columns=['z_score'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0PhnQojyP4J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "k4GAlaZ6yP0r",
        "outputId": "12ef22f8-d284-43e2-eb9a-d9a7b5f1a160"
      },
      "outputs": [],
      "source": [
        "# Compute max and min of the 'energy' column (excluding outliers)\n",
        "max_value = df.loc[\n",
        "    (df['is_iqr_outlier'] == 0) & (df['is_z_outlier'] == 0), 'energy'\n",
        "].max()\n",
        "\n",
        "min_value = df.loc[\n",
        "    (df['is_iqr_outlier'] == 0) & (df['is_z_outlier'] == 0), 'energy'\n",
        "].min()\n",
        "\n",
        "# Replace outliers in 'energy' column\n",
        "df['energy'] = np.where(\n",
        "    (df['is_iqr_outlier'] == 1) & (df['is_z_outlier'] == 1),\n",
        "    np.where(df['energy'] > max_value, max_value, min_value),\n",
        "    df['energy']\n",
        ")\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CQ_255MIGY0",
        "outputId": "e69d6281-905b-41cd-b1ea-522c0d38ba9e"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHZagadiIGVI"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PESbOSelIFpM"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s3ytP6QJV3_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WbyASUiJV0o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aIhXekxJVwf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoWaEiBmJVsQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qxy0PawiyPxI"
      },
      "outputs": [],
      "source": [
        "target_col = 'energy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuABUj9ayPtp"
      },
      "outputs": [],
      "source": [
        "# Split data into train and test sets by time order\n",
        "train_test_fraction = 0.88\n",
        "train_size = int(len(df) * train_test_fraction)\n",
        "\n",
        "# Splitting features and target\n",
        "X_train, X_test = df.iloc[:train_size].drop(columns=target_col), df.iloc[train_size:].drop(columns=target_col)\n",
        "Y_train, Y_test = df.iloc[:train_size][target_col], df.iloc[train_size:][target_col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B0j4988Vh4M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDchNTPcVhzV"
      },
      "outputs": [],
      "source": [
        "# Fit and transform specific columns\n",
        "X_train[['year', 'week_of_year', 'quarter', 'day_of_year', 'month', 'day_of_month', 'week_of_month', 'day_of_week', 'hour']] = scaler.fit_transform(\n",
        "    X_train[['year', 'week_of_year', 'quarter', 'day_of_year', 'month', 'day_of_month', 'week_of_month', 'day_of_week', 'hour']]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOuph6I-VhvU"
      },
      "outputs": [],
      "source": [
        "# Transform specific columns\n",
        "X_test[['year', 'week_of_year', 'quarter', 'day_of_year', 'month', 'day_of_month', 'week_of_month', 'day_of_week', 'hour']] = scaler.transform(\n",
        "    X_test[['year', 'week_of_year', 'quarter', 'day_of_year', 'month', 'day_of_month', 'week_of_month', 'day_of_week', 'hour']]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jO5QIIJKVhrG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuodxnfvVhnd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XylFZfU3yPqN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "SHnYjaUKyPm7",
        "outputId": "c763b70d-98de-465e-f09f-557e7ca6e384"
      },
      "outputs": [],
      "source": [
        "# Compute correlations, take absolute values, and sort by 'energy' in decreasing order\n",
        "corr_abs_sorted = pd.concat([X_train.drop(['datetime', 'is_z_outlier', 'is_iqr_outlier'], axis=1), Y_train], axis=1).corr()['energy'].abs().sort_values(ascending=False)\n",
        "corr_abs_sorted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VMnPWNP06jI",
        "outputId": "710db37b-37e2-4b20-9545-3baef65d15a1"
      },
      "outputs": [],
      "source": [
        "# Select the top 10 features (excluding 'energy' itself)\n",
        "feature_cols = corr_abs_sorted.drop(['energy']).index.tolist()  # Exclude the first entry (self-correlation)\n",
        "\n",
        "feature_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SI9B8jUy06gA"
      },
      "outputs": [],
      "source": [
        "x_train = X_train[feature_cols].values.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTVs0uMZ06cf"
      },
      "outputs": [],
      "source": [
        "x_test = X_test[feature_cols].values.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjcRciLC06YF",
        "outputId": "10127e49-769f-4ad3-b92c-5a3b71c75098"
      },
      "outputs": [],
      "source": [
        "x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNShrpbQ06Ur",
        "outputId": "30a9f6be-966f-448e-f270-84ec0209373c"
      },
      "outputs": [],
      "source": [
        "x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhTY-dYQ06Qq",
        "outputId": "f2a6deb4-5a31-4515-ec1a-001364a8784b"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_train = Y_train.values\n",
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jzd1eUrr06M6",
        "outputId": "59ee7cda-92d9-47fc-e8cf-8db38acd0633"
      },
      "outputs": [],
      "source": [
        "y_test = Y_test.values\n",
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CbXBFGk06I9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KK0Annxg06FE"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9eXlzSQ06Al"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPoB2jkn3-8V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtmEmavE4K7V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zRx5nPbkoM-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oISAHnU5GnT"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "  def __init__(self, features, labels):\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    self.features = torch.tensor(features, dtype=torch.float32)\n",
        "    self.labels = torch.tensor(labels, dtype=torch.float32)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.features[index], self.labels[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Thpv_XzP5z_b"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqAkmOzV58TD"
      },
      "outputs": [],
      "source": [
        "test_dataset = CustomDataset(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZq-FOc9Zdw4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ls-aqVizmTFm"
      },
      "outputs": [],
      "source": [
        "class MyNN(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, output_dim, num_hidden_layers, neurons_per_layer, dropout_rate):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    layers = []\n",
        "\n",
        "    for i in range(num_hidden_layers):\n",
        "\n",
        "      layers.append(nn.Linear(input_dim, neurons_per_layer))\n",
        "      layers.append(nn.BatchNorm1d(neurons_per_layer))\n",
        "      layers.append(nn.ReLU())\n",
        "      layers.append(nn.Dropout(dropout_rate))\n",
        "      input_dim = neurons_per_layer\n",
        "\n",
        "    layers.append(nn.Linear(neurons_per_layer, output_dim))\n",
        "\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQDEHhBwB3K7"
      },
      "outputs": [],
      "source": [
        "# Set device to CPU or GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)  # For multi-GPU setups\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Set random seed for other libraries\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_gylz_ElNc0"
      },
      "outputs": [],
      "source": [
        "best_modal_state = None  # Global variable to track the best modal state\n",
        "best_mape = float('inf')  # Initialize best MAPE with positive infinity (high value)\n",
        "\n",
        "\n",
        "# Objective function\n",
        "def objective(trial):\n",
        "    global best_modal_state, best_mape\n",
        "\n",
        "    # Hyperparameter suggestions\n",
        "    # Model Hyperparameters\n",
        "    num_hidden_layers = trial.suggest_int(\"num_hidden_layers\", 1, 7)\n",
        "    neurons_per_layer = trial.suggest_int(\"neurons_per_layer\", 64, 256, step=8)\n",
        "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5, step=0.1)\n",
        "\n",
        "    # Training Hyperparametrs\n",
        "    epochs = trial.suggest_int(\"epochs\", 20, 100, step=10)\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256])\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", ['Adam', 'SGD', 'RMSprop'])\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n",
        "\n",
        "    # Data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
        "\n",
        "    # Model initialization\n",
        "    input_dim = train_dataset.features.shape[1]  # Dynamically set input dimensions\n",
        "    output_dim = 1  # Regression task\n",
        "    model = MyNN(input_dim, output_dim, num_hidden_layers, neurons_per_layer, dropout_rate).to(device)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    if optimizer_name == 'Adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    elif optimizer_name == 'SGD':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    else:\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "\n",
        "\n",
        "    import torch\n",
        "    import torch.nn.functional as F\n",
        "\n",
        "    # Shifting model to device\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Initialize a list to store epoch-wise MAPE\n",
        "    epoch_mape_list = []\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_mape_train = 0  # Initialize total MAPE for the epoch\n",
        "        batch_count_train = 0  # Initialize batch counter\n",
        "\n",
        "        for batch_features, batch_labels in train_loader:\n",
        "            # Move data to device and ensure float32 dtype\n",
        "            batch_features = batch_features.to(device, dtype=torch.float32)\n",
        "            batch_labels = batch_labels.to(device, dtype=torch.float32)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_features)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = F.l1_loss(outputs, batch_labels.unsqueeze(1))\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculate training MAPE\n",
        "            mape = torch.mean(torch.abs((outputs - batch_labels.unsqueeze(1)) / (batch_labels.unsqueeze(1) + 1e-8)) * 100)\n",
        "            total_mape_train += mape.item()  # Accumulate MAPE for the epoch\n",
        "            batch_count_train += 1  # Increment batch counter\n",
        "\n",
        "        # Average MAPE for the epoch\n",
        "        avg_mape_train_epoch = total_mape_train / batch_count_train\n",
        "        epoch_mape_list.append(avg_mape_train_epoch)  # Store the epoch MAPE\n",
        "\n",
        "    # Calculate the average MAPE across all epochs\n",
        "    avg_mape_all_epochs = sum(epoch_mape_list) / len(epoch_mape_list)\n",
        "    print(f\"\\nAverage Train MAPE Across All Epochs: {avg_mape_all_epochs:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "    # Evaluation loop\n",
        "    model.eval()\n",
        "    total_mape = 0\n",
        "    batch_count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_features, batch_labels in test_loader:\n",
        "            # Move data to device\n",
        "            batch_features = batch_features.to(device, dtype=torch.float32)\n",
        "            batch_labels = batch_labels.to(device, dtype=torch.float32)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_features)\n",
        "\n",
        "            # Calculate batch-wise MAPE\n",
        "            batch_mape = torch.mean(torch.abs((outputs - batch_labels.unsqueeze(1)) / batch_labels.unsqueeze(1)) * 100)\n",
        "            total_mape += batch_mape.item()\n",
        "            batch_count += 1\n",
        "\n",
        "    # Average MAPE for the test set\n",
        "    avg_mape = total_mape / batch_count\n",
        "\n",
        "    if avg_mape < best_mape:\n",
        "      best_mape = avg_mape\n",
        "      best_modal_state = model.state_dict() # Save the best modal's weights\n",
        "\n",
        "    trial.set_user_attr(\"best_mape\", best_mape)\n",
        "    print(f\"Average Test MAPE: {avg_mape:.2f}%\")\n",
        "    return avg_mape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hyq6vN94VaO9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mvmh1sLJLCCb",
        "outputId": "298a4b1e-587b-4028-af19-1966a98182fc"
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAhkvuVVrBT3",
        "outputId": "38ba9593-1c98-48bf-e4d5-c44cf9d6da15"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "\n",
        "study = optuna.create_study(direction='minimize')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWXp7PEWrNPz",
        "outputId": "74abbafe-6188-450b-a24f-00403d376643"
      },
      "outputs": [],
      "source": [
        "study.optimize(objective, n_trials=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-bubVWNyO13",
        "outputId": "2254aba1-effd-437f-9d35-da2c6a9b1bb8"
      },
      "outputs": [],
      "source": [
        "# Initialize the best model with best hyperparameter\n",
        "best_trial = study.best_trial\n",
        "best_model = MyNN(\n",
        "    input_dim = train_dataset.features.shape[1],  # Dynamically set input dimension,\n",
        "    output_dim = 1,\n",
        "    num_hidden_layers = best_trial.params[\"num_hidden_layers\"],\n",
        "    neurons_per_layer = best_trial.params[\"neurons_per_layer\"],\n",
        "    dropout_rate = best_trial.params[\"dropout_rate\"]\n",
        ").to(device)\n",
        "\n",
        "# Load the saved best modal's weights from the best trial\n",
        "best_model.load_state_dict(best_modal_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5NrXu6Xyc5r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNSVCFZYyhsn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23Jnlgyq4aLT",
        "outputId": "aef1ab4f-0611-4e08-8431-d734a2e073de"
      },
      "outputs": [],
      "source": [
        "# Retrieve the best trial\n",
        "best_trial = study.best_trial\n",
        "print(\"Best trial hyperparameters:\", best_trial.params)\n",
        "print(\"Best trial value (Accuracy / Error) :\", best_trial.value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPi5oqsxScNj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7loZgmsHScJc"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataset):\n",
        "    best_model.eval()  # Set the model to evaluation mode\n",
        "    mape_list = []  # To store MAPE for each input\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for features, labels in DataLoader(dataset, batch_size=1, shuffle=False):\n",
        "            # Move features and labels to the device\n",
        "            features = features.to(device, dtype=torch.float32)\n",
        "            labels = labels.to(device, dtype=torch.float32)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(features)\n",
        "\n",
        "            # Compute MAPE with clamped labels to avoid division issues\n",
        "            mape = torch.abs((outputs - labels) / torch.clamp(labels, min=1e-2)) * 100\n",
        "            mape_list.append(mape.item())\n",
        "\n",
        "    # Calculate average MAPE\n",
        "    avg_mape = sum(mape_list) / len(mape_list)\n",
        "    return mape_list, avg_mape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3_a-bWBgj7V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rl66mlkzgj3o"
      },
      "outputs": [],
      "source": [
        "# Evaluate on training data\n",
        "train_mape_list, train_avg_mape = evaluate_model(best_model, train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRkn8atogj0C"
      },
      "outputs": [],
      "source": [
        "# Evaluate on test data\n",
        "test_mape_list, test_avg_mape = evaluate_model(best_model, test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zIJqCk6gzAj",
        "outputId": "60d4c25d-374c-4580-de89-87a8a256acb5"
      },
      "outputs": [],
      "source": [
        "# Print MAPE for each sample and average MAPE\n",
        "print(\"MAPE for each sample in Training Data:\")\n",
        "for i, mape in enumerate(train_mape_list):\n",
        "    f\"Sample {i + 1}: {mape:.4f}%\"\n",
        "print(f\"\\nAverage MAPE for Training Data: {train_avg_mape:.4f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYElpaFqgyw7",
        "outputId": "44ef5a26-8d9f-4105-b648-1e5e8a983282"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"\\nMAPE for each sample in Test Data:\")\n",
        "for i, mape in enumerate(test_mape_list):\n",
        "    f\"Sample {i + 1}: {mape:.4f}%\"\n",
        "print(f\"\\nAverage MAPE for Test Data: {test_avg_mape:.4f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHaSawP75jDT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgwOFxA-ScFr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Function to apply the model and create a DataFrame with actual and forecasted values\n",
        "def evaluate_and_create_df(model, dataset, dataset_name):\n",
        "    best_model.eval()\n",
        "    results = {\"Actual\": [], \"Forecasted\": []}  # Dictionary to store results\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for features, labels in DataLoader(dataset, batch_size=1, shuffle=False):\n",
        "            # Move features and labels to the device\n",
        "            features = features.to(device, dtype=torch.float32)\n",
        "            labels = labels.to(device, dtype=torch.float32)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(features)\n",
        "\n",
        "            # Append actual and forecasted values to the dictionary\n",
        "            results[\"Actual\"].append(labels.item())         # Convert label to scalar\n",
        "            results[\"Forecasted\"].append(outputs.item())    # Convert output to scalar\n",
        "\n",
        "    # Create DataFrame from results\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df[\"Dataset\"] = dataset_name  # Add a column for dataset identification\n",
        "\n",
        "    return results_df\n",
        "\n",
        "# Apply the best model to training and testing datasets\n",
        "train_results_df = evaluate_and_create_df(best_model, train_dataset, \"Train\")\n",
        "test_results_df = evaluate_and_create_df(best_model, test_dataset, \"Test\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xYGsslbEkuG",
        "outputId": "4f94cfbf-90c3-4026-8518-008c90ddaefb"
      },
      "outputs": [],
      "source": [
        "print(train_dataset.features[0])\n",
        "print(train_dataset.labels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55AQcv3yEuco",
        "outputId": "8fac6f73-ada6-4f9e-b5e7-c4045585ef08"
      },
      "outputs": [],
      "source": [
        "best_model(train_dataset[0][0].unsqueeze(0).to(device, dtype=torch.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1iCOchtGY4w",
        "outputId": "b347aecb-4287-4db2-f1ba-6337a9e3bd1a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Combine training and testing results into a single DataFrame\n",
        "results_df = pd.concat([train_results_df, test_results_df], ignore_index=True)\n",
        "final_results_df = pd.concat([df['datetime'], results_df], axis=1)\n",
        "\n",
        "# Save or print the final DataFrame\n",
        "print(final_results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlAt06o6Wvbf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKd-r0xHWvXz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-ipLI0AWvUU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "6aRATxoP4aAb",
        "outputId": "5ca0b77c-014f-4bad-8aa8-cf94210df7ae"
      },
      "outputs": [],
      "source": [
        "future_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "m9p9BnFMvcv9",
        "outputId": "bfa5ac5e-55be-45d4-8886-39a20a42456d"
      },
      "outputs": [],
      "source": [
        "full_dates_df = pd.concat([df[['datetime']], future_df[['datetime']]], axis=0).reset_index(drop=True)\n",
        "\n",
        "full_dates_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "0syqImzuvcsN",
        "outputId": "fdcfd4a2-bb7e-4694-b4a5-d07b53dc2119"
      },
      "outputs": [],
      "source": [
        "full_feature_dates_df = extract_date_features(full_dates_df)\n",
        "full_feature_dates_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5v55MqEUMJRq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97Tk7claqQmP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "vyaKk4u3qQbF",
        "outputId": "447d918c-9dd6-4f47-89c7-96dc794f7412"
      },
      "outputs": [],
      "source": [
        "# Fit and transform specific columns\n",
        "full_feature_dates_df[['year', 'week_of_year', 'quarter', 'day_of_year', 'month', 'day_of_month', 'week_of_month', 'day_of_week', 'hour']] = scaler.transform(\n",
        "    full_feature_dates_df[['year', 'week_of_year', 'quarter', 'day_of_year', 'month', 'day_of_month', 'week_of_month', 'day_of_week', 'hour']])\n",
        "full_feature_dates_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xq47UaQGqQTe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "rALbE-YB7a18",
        "outputId": "3eaa75ac-b05d-418a-f86a-36e3ab6d86af"
      },
      "outputs": [],
      "source": [
        "full_date_features_df = full_feature_dates_df[feature_cols]\n",
        "\n",
        "full_date_features_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gcVR6-lxKga"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7OCAwl8yRWX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddakL8SA7aub"
      },
      "outputs": [],
      "source": [
        "# Ensure the model is in evaluation mode\n",
        "best_model.eval()\n",
        "\n",
        "# Convert features to PyTorch tensor and move to the device\n",
        "features_tensor = torch.tensor(full_date_features_df.values.astype(np.float32), dtype=torch.float32).to(device)\n",
        "\n",
        "# Use the model to predict\n",
        "with torch.no_grad():  # No gradients are needed for inference\n",
        "    y_pred = best_model(features_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hqt9VvSUcq3F",
        "outputId": "10a7fc8c-193f-4020-ae57-caf8284759bc"
      },
      "outputs": [],
      "source": [
        "print(type(y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LryJw4Tba_Md"
      },
      "outputs": [],
      "source": [
        "# Move predictions to CPU if they are on a GPU, then convert to NumPy or list\n",
        "y_pred = y_pred.cpu().numpy()  # For a NumPy array\n",
        "\n",
        "y_pred_list = y_pred.tolist()  # For a Python list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGdJDWxO7aq6",
        "outputId": "94bbb59d-ccf0-43c9-d5eb-23b51d085abc"
      },
      "outputs": [],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SbDttWW7anT"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0UpGrju7akM"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_pred_df = pd.DataFrame(y_pred, columns=['energy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "8AxIoP5zLSWD",
        "outputId": "3111c04c-91ba-42a5-96dc-22cc053c1788"
      },
      "outputs": [],
      "source": [
        "y_pred_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "zifgTkhdLSOc",
        "outputId": "f6528402-9ee5-41db-a6b9-b319f331b9e8"
      },
      "outputs": [],
      "source": [
        "full_dates_df['datetime']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "XpQTjO4NLSHb",
        "outputId": "5b0d7bd1-54d2-4f9c-d396-cf4cdc6b0668"
      },
      "outputs": [],
      "source": [
        "pred_df = pd.concat([full_dates_df['datetime'], y_pred_df], axis=1)\n",
        "pred_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csyhTuowL21s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsouwJazL2vZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set 'datetime' as the index for both DataFrames\n",
        "df.set_index('datetime', inplace=True)\n",
        "pred_df.set_index('datetime', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qMK_bB6L2r8"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Resample the data by month, summing the energy values\n",
        "df_monthly = df['energy' ].resample('ME').sum()\n",
        "pred_df_monthly = pred_df.resample('ME').sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "OhwTEpZBL2qx",
        "outputId": "7214eb1c-ab84-4dd0-944e-791ab9f01d98"
      },
      "outputs": [],
      "source": [
        "df_monthly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KHl4A7cW3L7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "KpZjN3PuQTxE",
        "outputId": "eb0c1317-c75e-4c8e-ad5b-54d2313019a8"
      },
      "outputs": [],
      "source": [
        "pred_df_monthly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV0Avql6XNAz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "xSpouyxmaD7J",
        "outputId": "0bf1ce2c-a69c-4c30-ca34-b4a17fe916c5"
      },
      "outputs": [],
      "source": [
        "merged = pd.concat([df_monthly, pred_df_monthly], axis=1, keys=['Actual', 'Predicted'])\n",
        "merged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-0KcCfCaDi6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "V_yO_dIlXM9k",
        "outputId": "f96d32b5-7b7a-4ea3-aa78-bf7c8cfec7dc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the data\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(merged.index, merged[('Actual', 'energy')], label='Actual Energy', color='blue', marker='o')\n",
        "plt.plot(merged.index, merged[('Predicted', 'energy')], label='Predicted Energy', color='orange', linestyle='--', marker='x')\n",
        "\n",
        "# Set labels and title\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Energy')\n",
        "plt.title('Energy Consumption Forecasting: Actual vs Predicted by Month')\n",
        "\n",
        "# Show legend\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "# Rotate x-axis labels for better readability\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# Set the background color to light green\n",
        "plt.gcf().set_facecolor('lightgreen')\n",
        "\n",
        "# Add text for train-test split and data ranges\n",
        "info_text = (\n",
        "    \"MAPE = 6%\\n\"\n",
        "    \"Train Data: 2008-2016\\n\"\n",
        "    \"Test Data: 2016-2018\\n\"\n",
        "    \"Predicted Data: 2018-2020\\n\"\n",
        "    \"Data: Hourly, Grouped by Month\"\n",
        ")\n",
        "plt.text(0.02, 0.95, info_text, transform=plt.gca().transAxes,\n",
        "         fontsize=10, verticalalignment='top', bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor='black', facecolor='lightgrey'))\n",
        "\n",
        "# Display the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nm9ZQ4ceXM6N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPhrXcjmQTtI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiZ-Q7F_Vv8B"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
